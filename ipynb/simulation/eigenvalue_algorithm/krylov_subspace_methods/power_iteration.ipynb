{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f18761a",
   "metadata": {},
   "source": [
    "#### Power Iteration Method\n",
    "``` txt\n",
    "    幂迭代法(Power Iteration Method)是一种寻找矩阵最大本征值及其对应本征向量的简单方法。其核心思想是，对一个随机向量反复左乘一个矩阵 A，\n",
    "经过足够多次迭代后，向量的方向将收敛于 A 的主导本征向量。\n",
    "```\n",
    "* [Power_iteration wikipedia](https://en.wikipedia.org/wiki/Power_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c894036",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def power_iteration(A, max_iter=100, tol=1e-6):\n",
    "    # 获取矩阵大小\n",
    "    n = A.shape[0]\n",
    "    \n",
    "    # 随机初始向量\n",
    "    u = np.random.rand(n)\n",
    "    u = u / np.linalg.norm(u)\n",
    "    \n",
    "    calc_err_v0 = lambda u_new, u : np.linalg.norm(u_new - u)\n",
    "    # v1 版本比 v0 好的地方在于, 可以处理 u_new 和 u 方向相反的情况\n",
    "    calc_err_v1 = lambda u_new, u : 1- abs(np.dot(u_new, u))\n",
    "\n",
    "    for i in range(max_iter):\n",
    "        Au = A @ u\n",
    "        u_new = Au / np.linalg.norm(Au)\n",
    "        \n",
    "        err = calc_err_v1(u_new, u)\n",
    "\n",
    "        if err < tol or i == max_iter - 1:\n",
    "            print(f\"Converged at iteration {i}, error={err}\")\n",
    "            break\n",
    "        \n",
    "        u = u_new\n",
    "    \n",
    "    # 瑞利商计算特征值\n",
    "    eigenvalue = (u.T @ A @ u) / (u.T @ u)\n",
    "    return eigenvalue, u\n",
    "\n",
    "def find_top_eigenvalues(A, num_eigenvalues=2, max_iter=100, tol=1e-6):\n",
    "    \"\"\"\n",
    "    找到前几个最大的特征值和对应的特征向量\n",
    "    \n",
    "    参数:\n",
    "    A: 输入矩阵\n",
    "    num_eigenvalues: 需要找到的特征值数量\n",
    "    max_iter: 最大迭代次数\n",
    "    tol: 收敛容差\n",
    "    \n",
    "    返回:\n",
    "    eigenvalues: 特征值列表（从大到小）\n",
    "    eigenvectors: 对应的特征向量列表\n",
    "    \"\"\"\n",
    "    n = A.shape[0]\n",
    "    eigenvalues = []\n",
    "    eigenvectors = []\n",
    "    A_current = A.copy()\n",
    "    \n",
    "    for i in range(num_eigenvalues):\n",
    "        print(f\"Finding eigenvalue {i+1}...\")\n",
    "        \n",
    "        # 使用幂迭代法找到当前最大特征值\n",
    "        eigenvalue, eigenvector = power_iteration(A_current, max_iter, tol)\n",
    "        eigenvalues.append(eigenvalue)\n",
    "        eigenvectors.append(eigenvector)\n",
    "        \n",
    "        # 如果是最后一个特征值，不需要继续收缩\n",
    "        if i == num_eigenvalues - 1:\n",
    "            break\n",
    "            \n",
    "        # 使用收缩技术：A = A - λ * v * v^T\n",
    "        # 这会将当前特征值对应的分量从矩阵中移除\n",
    "        outer_product = np.outer(eigenvector, eigenvector)\n",
    "        A_current = A_current - eigenvalue * outer_product\n",
    "        \n",
    "        print(f\"Found eigenvalue {i+1}: {eigenvalue}\")\n",
    "    \n",
    "    return eigenvalues, eigenvectors\n",
    "\n",
    "\n",
    "def find_eigenvalue_close_to_sigma(A, sigma=0, max_iter=100, tol=1e-6):\n",
    "    \"\"\"\n",
    "    逆幂法求最接近sigma的特征值\n",
    "    \n",
    "    参数:\n",
    "    A: 输入矩阵 (n x n)\n",
    "    sigma: 目标特征值的估计值（移位量）\n",
    "    max_iter: 最大迭代次数\n",
    "    tol: 收敛容差\n",
    "    \n",
    "    返回:\n",
    "    eigenvalue: 最接近sigma的特征值\n",
    "    eigenvector: 对应的特征向量\n",
    "    \"\"\"\n",
    "    n = A.shape[0]\n",
    "    \n",
    "    # 构造移位矩阵: (A - σI)\n",
    "    shifted_A = A - sigma * np.eye(n)\n",
    "    \n",
    "    try:\n",
    "        # 计算移位矩阵的逆\n",
    "        inv_shifted_A = np.linalg.inv(shifted_A)\n",
    "    except np.linalg.LinAlgError:\n",
    "        raise ValueError(\"Matrix (A - σI) is singular, choose a different sigma\")\n",
    "    \n",
    "    # 对逆矩阵使用幂迭代法求最大特征值\n",
    "    # 注意：inv_shifted_A 的最大特征值对应 A 的最接近sigma的特征值\n",
    "    inv_eigenvalue, eigenvector = power_iteration(inv_shifted_A, max_iter, tol)\n",
    "    \n",
    "    # 转换回原矩阵的特征值\n",
    "    # 如果 μ 是 inv_shifted_A 的特征值，那么 1/μ 是 shifted_A 的特征值\n",
    "    # 所以 A 的特征值为：λ = σ + 1/μ\n",
    "    eigenvalue = sigma + 1.0 / inv_eigenvalue\n",
    "    \n",
    "    return eigenvalue, eigenvector\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0459f157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original matrix A:\n",
      "[[0.74908024 1.10670883 0.75257844 0.78206299 0.76787154]\n",
      " [1.10670883 0.11616722 1.836086   0.90535725 0.84756644]\n",
      " [0.75257844 1.836086   1.66488528 0.73709554 0.47396962]\n",
      " [0.78206299 0.90535725 0.73709554 0.86389004 0.65759098]\n",
      " [0.76787154 0.84756644 0.47396962 0.65759098 0.91213997]]\n",
      "Finding eigenvalue 1...\n",
      "Converged at iteration 5, error=3.0967639486068066e-07\n",
      "Found eigenvalue 1: 4.528957572646465\n",
      "Finding eigenvalue 2...\n",
      "Converged at iteration 25, error=5.476318717390072e-07\n",
      "\n",
      "Results:\n",
      "Largest eigenvalue: 4.528957572646465\n",
      "Second largest eigenvalue: -1.3140917618429957\n",
      "\n",
      "Validation with numpy.linalg.eig:\n",
      "Largest eigenvalue (numpy): 4.528959747929156\n",
      "Second largest eigenvalue (numpy): -1.3140851205023023\n"
     ]
    }
   ],
   "source": [
    "# 创建一个对称矩阵（确保实数特征值）\n",
    "np.random.seed(42)\n",
    "n = 5\n",
    "B = np.random.rand(n, n)\n",
    "A = B + B.T  # 使矩阵对称\n",
    "\n",
    "print(\"Original matrix A:\")\n",
    "print(A)\n",
    "\n",
    "# 找到前两个特征值\n",
    "eigenvalues, eigenvectors = find_top_eigenvalues(A, num_eigenvalues=2)\n",
    "\n",
    "print(\"\\nResults:\")\n",
    "print(f\"Largest eigenvalue: {eigenvalues[0]}\")\n",
    "print(f\"Second largest eigenvalue: {eigenvalues[1]}\")\n",
    "\n",
    "# 验证结果（使用numpy的eig函数）\n",
    "eigvals, eigvecs = np.linalg.eig(A)\n",
    "sorted_indices = np.argsort(np.abs(eigvals))[::-1]  # 按模长从大到小排序\n",
    "sorted_eigvals = eigvals[sorted_indices]\n",
    "\n",
    "print(\"\\nValidation with numpy.linalg.eig:\")\n",
    "print(f\"Largest eigenvalue (numpy): {sorted_eigvals[0]}\")\n",
    "print(f\"Second largest eigenvalue (numpy): {sorted_eigvals[1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a717add",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged at iteration 2, error=1.752098743867947e-07\n",
      "searched eigenvalues=-1.3140851253930066, eigenvectors=[ 0.22028203 -0.86027191  0.43033994  0.09312722  0.13244973]\n"
     ]
    }
   ],
   "source": [
    "eigenvalues, eigenvectors = find_eigenvalue_close_to_sigma(A, sigma=-1.3)\n",
    "print(f\"searched eigenvalues={eigenvalues}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0779509a",
   "metadata": {},
   "source": [
    "```txt\n",
    "    如果 power ieration 还有不明白的地方, 可以了解一下前置知识 Gram-Schmidt 正交分解，\n",
    "在有了 power iteration 基础后，可以了解一下 Krylov 子空间迭代法和 Lanczos 方法。\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_running",
   "language": "python",
   "name": "venv_running"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
